{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "189be264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This line has been inserted as Github commit test\n",
    "\n",
    "def qld_data(datetime,requests,ET,pd):\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    now = now.strftime('%Y%m%d-%H%M%S')\n",
    "    \n",
    "    qld_fire_data = 'data/qld_data/qld_fire_data_'+now+'.xml'\n",
    "    \n",
    "        #add the data from the website \n",
    "    URL = \"https://www.qfes.qld.gov.au/data/alerts/bushfireAlert.xml\"\n",
    "    \n",
    "    #The binary mode (wb) is required to write the actual content of the XML page to your external file in the original format.\n",
    "    #will get the current up to date details from website\n",
    "    response = requests.get(URL)\n",
    "    with open(qld_fire_data, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "        \n",
    "    #parse through the data    \n",
    "    mytree = ET.parse(qld_fire_data) \n",
    "    myroot = mytree.getroot()\n",
    "\n",
    "    geo_list=[]\n",
    "    for geo in myroot.findall('.//{http://www.georss.org/georss}point'):\n",
    "        geo_list.append(geo.text)\n",
    "\n",
    "    co_ordinates_split =[]\n",
    "    for value in geo_list:\n",
    "        co_ordinates_split.append(value.split())\n",
    "\n",
    "    qld_latitude_list = []\n",
    "    qld_longitude_list = []\n",
    "    for co_ordinates in co_ordinates_split:\n",
    "        qld_latitude_list.append(co_ordinates[0])\n",
    "        qld_longitude_list.append(co_ordinates[1])\n",
    "    \n",
    "    report_date = datetime.date.today()\n",
    "    report_date = report_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    qld_df = pd.DataFrame({\n",
    "        'Latitude': qld_latitude_list,\n",
    "        'Longitude': qld_longitude_list,\n",
    "        'State': 'QLD',\n",
    "        'Report Date': report_date\n",
    "    })\n",
    "    \n",
    "    #Do we need these steps for our end code or should we go straight to S3 rather than saving it down\n",
    "    qld_df.to_csv(\"data/fire_data.csv\", mode = 'a', index = False , header = False)\n",
    "\n",
    "    #remove duplicate values\n",
    "    fire_data_df = pd.read_csv('data/fire_data.csv')\n",
    "\n",
    "    #drop the duplicates out of the data frame\n",
    "    distinct_fire_data = fire_data_df.drop_duplicates()\n",
    "\n",
    "    #create a new csv file with the dropped duplicate values\n",
    "    distinct_fire_data.to_csv('data/fire_data_distinct.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f5989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
